#!/bin/bash -eu

#
# Copyright (c) 2017, Carnegie Mellon University.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
# 3. Neither the name of the University nor the names of its contributors
#    may be used to endorse or promote products derived from this software
#    without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT
# HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
# OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED
# AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY
# WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
#


#
# global variables we set/use:
#  $dfsu_prefix - deltafs umbrella prefix directory (abspath)
#  $ip_subnet - the ip subnet we want to use (x.y.z.t)
#  $jobdir - per-job shared output directory (abspath)
#  $logfile - log shared by all exp runs (abspath)
#  $exp_logfile - log used by one specific exp run (abspath)
#  $nodes - number of nodes for vpic (int)
#  $bbos_buddies - number of nodes for bbos (int)
#  $cores - total cores across all nodes (int)
#  $all_nodes - list of all nodes (string - sep: comma)
#  $vpic_nodes - list of nodes for vpic (string - sep: comma)
#  $bbos_nodes - list of nodes for bbos (string - sep: comma)
#  $bb_log_size - BBOS max per-core log size in bytes
#  $do_querying - whether we will perform particle queries (bool - 0 or 1)
#

# environment variables we set/use:
#  $JOBDIRHOME - where to put job dirs (default: $HOME/jobs)
#                example: /lustre/ttscratch1/users/$USER
#  $EXTRA_MPIOPTS - additional options that need to be passed to mpirun
#

#
# environment variables we use as input:
#  $HOME - your home directory
#  $MOAB_JOBNAME - jobname (cray)
#  $PBS_JOBID - job id (cray)
#  $PBS_NODEFILE - file with list of all nodes (cray)
#  $DW_JOB_STRIPED - data wrap mount (cray)
#

#
# files we create:
#  $jobdir/hosts.txt - list of hosts
#  $jobdir/bbos.hosts - host file only of bbos hosts
#  $jobdir/vpic.hosts - host file only of vpic hosts
#

# TODO:
# - Convert node lists to ranges on CRAY

#
# prefix directory comes from cmake's ${CMAKE_INSTALL_PREFIX} variable
#
dfsu_prefix=@CMAKE_INSTALL_PREFIX@

### ensure definition of a set of global vars ###

#
# number of epochs for VPIC runs
# default: 8
#
vpic_epochs=${vpic_epochs:-8}

#
# job-wise log - shared among all exp runs
# default: null
#
logfile=${logfile-}

#
# exp-wise log - one per exp run
# default: null
#
exp_logfile=${exp_logfile-}

#
# num of bbos nodes to use
# default: 0
#
bbos_buddies=${bbos_buddies:-0}

#
# if a read phase should follow a write phase
# default: 0
#
do_querying=${do_querying:-0}

#
# message: echo message to stdout, cc it to a default job-wise log file, and
# then cc it again to a specific exp-wise log file.
# note that if either $logfile or $exp_logfile is empty, tee will
# just print the message without writing to files
# uses: $logfile, $exp_logfile
#
message () { echo "$@" | tee -a $exp_logfile | tee -a $logfile; }

#
# die: emit a mesage and exit 1
#
die () { message "!!! ERROR !!! $@"; exit 1; }

#
# jobdir  ## Lustre
#
# get_jobdir: setup $jobdir var and makes sure $jobdir is present
# uses: $MOAB_JOBNAME, $PBS_JOBID, $JOBDIRHOME
# sets: $jobdir
#
get_jobdir() {
    if [ x${JOBDIRHOME-} != x ]; then
        jobdirhome=${JOBDIRHOME}
    else
        jobdirhome=${HOME}/jobs
    fi
    if [ x${MOAB_JOBNAME-} != x ]; then
        jobdir=${jobdirhome}/${MOAB_JOBNAME}.${PBS_JOBID-}
    else
        jobdir=${jobdirhome}/`basename $0`.$$  # use top-level script name $0
    fi
    message "-INFO- creating jobdir..."
    mkdir -p ${jobdir} || die "cannot make jobdir ${jobdir}"
    logfile=${jobdir}/$(basename $jobdir).log ### XXX: auto set logfile
    bbdir=${jobdir} ### XXX: auto set bbdir
    message "-INFO- jobdir = ${jobdir}"
}

#
# bbdir  ## shared XFS on CN only
#
# get_bbdir: setup $bbdir var and makes sure $bbdir is present, otherwise
# falls back to $jobdir if BB is not available
# uses: $DW_JOB_STRIPED, $jobdir
# sets: $bbdir
#
get_bbdir() {
    if [ x${DW_JOB_STRIPED-} = x ]; then
      bbdir=${jobdir}
      message "!!! WARNING !!! missing DW_JOB_STRIPED - putting data in jobdir for this test"
    else
      dwsessid=$(dwcli ls session)
      dwconfid=$(dwcli ls configuration)
      message "-INFO- >>> dwsessid=$dwsessid | dwconfid=$dwconfid"
      jobdir_last_component=$(basename $jobdir)
      bbdir="${DW_JOB_STRIPED}/$jobdir_last_component"
      message "-INFO- creating bbdir..."
      do_mpirun 1 1 "" "" "mkdir -p ${bbdir}"
      do_mpirun 1 1 "" "" "ls ${bbdir}"
      message "-INFO- bbdir = ${bbdir}"
    fi
}

#
# all_nodes
#
# gen_hostfile: generate a list of hosts we have in $jobdir/hosts.txt
# one host per line.
# uses: $PBS_NODEFILE, $jobdir
# sets: $all_nodes
# creates: $jobdir/hosts.txt
#
gen_hostfile() {
    message "-INFO- generating hostfile ${jobdir}/hosts.txt..."

    if [ `which aprun` ]; then
        # Generate hostfile on CRAY and store on disk
        cat $PBS_NODEFILE | uniq | sort > $jobdir/hosts.txt || \
            die "failed to create hosts.txt file"

    else
        # Generate hostfile on Emulab and store on disk
        fqdn_suffix="`hostname | sed 's/^[^\.]*././'`"
        exp_hosts="`/share/testbed/bin/emulab-listall | tr ',' '\n' | \
                    sed 's/$/'$fqdn_suffix'/g'`"

        echo "$exp_hosts" > $jobdir/hosts.txt || \
            die "failed to create hosts.txt file"
    fi

    # Populate a variable with hosts
    all_nodes=$(cat ${jobdir}/hosts.txt)
    num_all_nodes=$(cat ${jobdir}/hosts.txt | tr ',' '\n' | sort | wc -l)
    message "-INFO- num hosts = ${num_all_nodes}"
}

#
# generate host list files: $jobdir/vpic.hosts, $jobdir/bbos.hosts
# uses: $PBS_NODEFILE, $jobdir, $nodes, $bbos_buddies
# sets: $vpic_nodes, $bbos_nodes
# creates: $jobdir/vpic.hosts, $jobdir/bbos.hosts
#
gen_hosts() {
    message "-INFO- generating host lists..."

    # XXX: sanity check: # of nodes in list from PBS_NODEFILE or
    # XXX:               emulab-listall >= $nodes+$bbos_buddies

    if [ `which aprun` ]; then
        # Generate host lists on CRAY and store them on disk
        cat $PBS_NODEFILE | uniq | sort > $jobdir/hosts.txt || \
            die "failed to create hosts.txt file"

        cat $jobdir/hosts.txt | head -n $nodes | \
            tr '\n' ',' | sed '$s/,$//' > $jobdir/vpic.hosts || \
            die "failed to create vpic.hosts file"
        cat $jobdir/hosts.txt | tail -n $bbos_buddies | \
            tr '\n' ',' | sed '$s/,$//' > $jobdir/bbos.hosts || \
            die "failed to create bbos.hosts file"

    else
        # Generate host lists on Emulab and store them on disk
        fqdn_suffix="`hostname | sed 's/^[^\.]*././'`"
        exp_hosts="`/share/testbed/bin/emulab-listall | tr ',' '\n' | \
                    sed 's/$/'$fqdn_suffix'/g'`"

        echo "$exp_hosts" | head -n $nodes | \
            tr '\n' ',' | sed '$s/,$//' > $jobdir/vpic.hosts || \
            die "failed to create vpic.hosts file"
        echo "$exp_hosts" | tail -n $bbos_buddies | \
            tr '\n' ',' | sed '$s/,$//' > $jobdir/bbos.hosts || \
            die "failed to create bbos.hosts file"
    fi

    ### set host list variables ###

    vpic_nodes=$(cat ${jobdir}/vpic.hosts)
    num_vpic_nodes=$(cat ${jobdir}/vpic.hosts | tr ',' '\n' | sort | wc -l)
    message "-INFO- num vpic nodes = ${num_vpic_nodes}"

    bbos_nodes=$(cat ${jobdir}/bbos.hosts)
    num_bbos_nodes=$(cat ${jobdir}/bbos.hosts | tr ',' '\n' | sort | wc -l)
    message "-INFO- num bbos nodes = ${num_bbos_nodes}"
}

#
# clear_caches: clear node caches on vpic nodes
# uses: $vpic_nodes, $cores, $nodes
#
clear_caches() {
    message "-INFO- clearing node caches..."

    if [ `which aprun` ]; then
        message "!!! WARNING !!! skipping cache clear ... no sudo access on cray"
        #aprun -L $vpic_nodes -n $cores -N $nodes sudo sh -c \
        #    'echo 3 > /proc/sys/vm/drop_caches'
    else
        # this does more than just $vpic_nodes (does them all)
        /share/testbed/bin/emulab-mpirunall sudo sh -c \
            'echo 3 > /proc/sys/vm/drop_caches'
    fi

    message "-INFO- done"
}

#
# do_mpirun: Run CRAY MPICH, ANL MPICH, or OpenMPI run command
#
# Arguments:
# @1 number of processes
# @2 number of processes per node
# @3 array of env vars: ("name1", "val1", "name2", ... )
# @4 host list (comma-separated)
# @5 executable (and any options that don't fit elsewhere)
# @6 extra_opts: extra options to mpiexec (optional)
# @7 log1: primary log file for mpi stdout (optional)
# @8 log2: secondary log file for mpi stdout (optional)
do_mpirun() {
    procs=$1
    ppnode=$2
    if [ ! -z "$3" ]; then
        declare -a envs=("${!3}")
    else
        envs=()
    fi
    hosts="$4"
    exe="$5"
    ### extra options to mpiexec ###
    extra_opts=${6-}
    ### log files ###
    log1=${7-$logfile}
    log2=${8-$exp_logfile}

    envstr=""; npstr=""; hstr=""

    if [ `which aprun` ]; then
        # This is likely a CRAY machine. Deploy an aprun job.

        if [ ${#envs[@]} -gt 0 ]; then
            envstr=`printf -- "-e %s=%s " ${envs[@]}`
        fi

        if [ $ppnode -gt 0 ]; then
            npstr="-N $ppnode"
        fi

        if [ ! -z "$hosts" ]; then
            hstr="-L $hosts"
        fi

        message "[MPIEXEC]" "aprun -n $procs" $npstr $hstr $envstr $extra_opts \
            ${DEFAULT_MPIOPTS-} $exe
        aprun -n $procs $npstr $hstr $envstr $extra_opts \
            ${DEFAULT_MPIOPTS-} $exe 2>&1 | \
            tee -a $log2 | tee -a $log1

    elif [ `which mpirun.mpich` ]; then
        if [ ${#envs[@]} -gt 0 ]; then
            envstr=`printf -- "-env %s %s " ${envs[@]}`
        fi

        if [ $ppnode -gt 0 ]; then
            npstr="-ppn $ppnode"
        fi

        if [ ! -z "$hosts" ]; then
            hstr="--host $hosts"
        fi

        message "[MPIEXEC]" "mpirun.mpich -np $procs" $npstr $hstr $envstr $extra_opts \
            ${DEFAULT_MPIOPTS-} $exe
        mpirun.mpich -np $procs $npstr $hstr $envstr $extra_opts \
            ${DEFAULT_MPIOPTS-} $exe 2>&1 | \
            tee -a $log2 | tee -a $log1

    elif [ `which mpirun.openmpi` ]; then
        if [ ${#envs[@]} -gt 0 ]; then
            envstr=`printf -- "-x %s=%s " ${envs[@]}`
        fi

        if [ $ppnode -gt 0 ]; then
            npstr="-npernode $ppnode"
        fi

        if [ ! -z "$hosts" ]; then
            hstr="--host $hosts"
        fi

        message "[MPIEXEC]" "mpirun.openmpi -n $procs" $npstr $hstr $envstr $extra_opts \
            ${DEFAULT_MPIOPTS-} $exe
        mpirun.openmpi -n $procs $npstr $hstr $envstr $extra_opts \
            ${DEFAULT_MPIOPTS-} $exe 2>&1 | \
            tee -a $log2 | tee -a $log1

    else
        die "could not find a supported mpirun or aprun command"
    fi
}

#
# build_deck: build a vpic deck by copying the deck template to the jobdir,
# adjusting config.h, and then compiling it using the vpic-build.op script.
# the result is placed in $jobdir/current-deck.op (XXX: assume you are only
# going to have one compiled deck at a time).
#
# uses: $dfsu_prefix, $jobdir, $cores
# creates: $jobdir/current-deck.op
#
# Arguments:
# @1 in {"file-per-process", "file-per-particle"}
# @2 particles on x dimension
# @3 particles on y dimension
# @4 particles on z dimension
#
build_deck() {
    px=$2
    py=$3
    pz=$4

    ddir=${jobdir}/tmpdeck.$$     # tmp staging area for stacking the deck
    rm -rf ${ddir}
    cp -r ${dfsu_prefix}/decks ${ddir}
    mv ${ddir}/trecon-part/config.h ${ddir}/trecon-part/config.bkp || \
        die "mv failed"

    message "--------------- [INPUT-DECK] --------------"
    message "!!! NOTICE !!! building vpic deck >> $1 >> cores = ${cores}, px = ${px}, py = ${py}, pz = ${pz}"
    message ""

    case $1 in
    "file-per-process")
        cat ${ddir}/trecon-part/config.bkp | \
            sed 's/#define VPIC_DUMPS.*/#define VPIC_DUMPS '$vpic_epochs'/' | \
            sed 's/^#define VPIC_FILE_PER_PARTICLE/\/\/#define VPIC_FILE_PER_PARTICLE/' | \
            sed 's/VPIC_TOPOLOGY_X.*/VPIC_TOPOLOGY_X 1/' | \
            sed 's/VPIC_TOPOLOGY_Y.*/VPIC_TOPOLOGY_Y '$cores'/' | \
            sed 's/VPIC_TOPOLOGY_Z.*/VPIC_TOPOLOGY_Z 1/' | \
            sed 's/VPIC_PARTICLE_X.*/VPIC_PARTICLE_X '$px'/' | \
            sed 's/VPIC_PARTICLE_Y.*/VPIC_PARTICLE_Y '$py'/' | \
            sed 's/VPIC_PARTICLE_Z.*/VPIC_PARTICLE_Z '$pz'/' >  \
                   ${ddir}/trecon-part/config.h || \
            die "config.h editing failed"
        ;;
    "file-per-particle")
        cat ${ddir}/trecon-part/config.bkp | \
            sed 's/#define VPIC_DUMPS.*/#define VPIC_DUMPS '$vpic_epochs'/' | \
            sed 's/^\/\/#define VPIC_FILE_PER_PARTICLE/#define VPIC_FILE_PER_PARTICLE/' | \
            sed 's/VPIC_TOPOLOGY_X.*/VPIC_TOPOLOGY_X '$cores'/' | \
            sed 's/VPIC_TOPOLOGY_Y.*/VPIC_TOPOLOGY_Y 1/' | \
            sed 's/VPIC_TOPOLOGY_Z.*/VPIC_TOPOLOGY_Z 1/' | \
            sed 's/VPIC_PARTICLE_X.*/VPIC_PARTICLE_X '$px'/' | \
            sed 's/VPIC_PARTICLE_Y.*/VPIC_PARTICLE_Y '$py'/' | \
            sed 's/VPIC_PARTICLE_Z.*/VPIC_PARTICLE_Z '$pz'/' >  \
                   ${ddir}/trecon-part/config.h || \
            die "config.h editing failed"
        ;;
    *)
        die "build_deck: VPIC mode not supported"
        ;;
    esac

    # Compile input deck
    (cd ${ddir}/trecon-part && ${dfsu_prefix}/bin/vpic-build.op ./turbulence.cxx \
       2>&1 | tee -a $exp_logfile | tee -a $logfile) || \
           die "compilation failed"

    mv ${ddir}/trecon-part/turbulence.op ${jobdir}/current-deck.op || \
        die "install new current deck failed"

    message ""
    message "[DECK] --- $(ls -lni --full-time ${jobdir}/current-deck.op)"
    message ""

    message "-INFO- vpic deck installed at ${jobdir}/current-deck.op"
    message "--------------- [    OK    ] --------------"

    # don't need staging area anymore
    rm -rf ${ddir}
}

#
# do_run: run a vpic experiment
#
# uses: $dfsu_prefix, $jobdir, $bbdir, $cores, $nodes, $logfile, $vpic_nodes,
#        $bb_log_size, $bbos_buddies
#        $jobdir/current-deck.op (precompiled deck)
#        $jobdir/bbos.hosts, $jobdir/vpic.hosts
# creates: an experiment tag: {runtype}_P{particles}_C${cores}_N${nodes}
#          $bbdir/$exp_tag - primary output directory for the experiment
#          $jobdir/$exp_tag - secondary output directory for the experiment
#          $jobdir/$exp_tag/$exp_tag.log - logfile for the experiment
# side effects: changes current directory to $jobdir/$exp_tag
#
# Arguments:
# @1 experiment type in {"baseline", "deltafs", "shuffle_test"}
# @2 number of particles
# @3 ppn
do_run() {
    runtype=$1
    p=$2
    ppn=${3:-0}

    # pp: make a more human readable version of "p"
    if [ $((p / (10**6))) -gt 0 ]; then
        pp="$((p / (10**6)))M"
    elif [ $((p / (10**3))) -gt 0 ]; then
        pp="$((p / (10**3)))K"
    else
        pp="$p"
    fi

    exp_tag="${runtype}_P${pp}_C${cores}_N${nodes}"
    cd $jobdir || die "cd to $jobdir failed"
    exp_jobdir="$jobdir/$exp_tag"   ### NOTE !! still on Lustre !! ###
    mkdir -p $exp_jobdir || die "mkdir $exp_jobdir failed"
    cd $exp_jobdir || die "cd to $exp_jobdir failed"
    ### log file for this exp ###
    exp_logfile="$exp_jobdir/$exp_tag.log"   ### NOTE !! absolute path !! ###

    message "--------------- [   DOIT   ] --------------"
    message "!!! NOTICE !!! starting exp >> >> ${exp_tag}..."
    message ""

    ### ATTENTION: data might go to bb ###
    exp_dir="$bbdir/$exp_tag"
    message "-INFO- creating exp dir..."
    do_mpirun 1 1 "" "" "mkdir -p ${exp_dir}"
    message "-INFO- done"

    ### NOTE: cannot cd to $exp_dir since it may land in bb ###

    clear_caches

    message ""
    message "[DECK] --- $(ls -lni --full-time ${jobdir}/current-deck.op)"
    message ""

    ### SPAM ENOUGH TO MAKE BOSS HAPPY ###
    message "=================================================================="
    message "!!! Running VPIC ($runtype) with $pp particles on $cores cores and $nodes nodes !!!"
    message "------------"
    message "> Using ${jobdir}/current-deck.op"
    message "> Job dir is ${jobdir}"
    message "> Experiment dir is ${exp_dir}"
    message "> Log to ${exp_logfile}"
    message "  (+) Log to ${logfile}"
    message "      (+) Log to STDOUT"
    message "=================================================================="
    message ""

    case $runtype in
    "baseline")
        vpic_dir=$exp_dir/vpic

        ### BOOTSTRAPING ###
        message "-INFO- creating more exp dirs..."
        do_mpirun 1 1 "" "" "mkdir -p $vpic_dir"
        message "-INFO- done"

        ### WRITE PATH ###
        env_vars=("VPIC_current_working_dir" "$vpic_dir")
        do_mpirun $cores $ppn env_vars[@] "$vpic_nodes" "${jobdir}/current-deck.op" \
            "${EXTRA_MPIOPTS-}"

        message ""
        message "-INFO- checking output size..."
        do_mpirun 1 1 "" "" "du -sb $vpic_dir/particle" | tee -a $exp_jobdir/outsize.txt
        echo "Output size:" `cat $exp_jobdir/outsize.txt | \
            grep -F -v "[MPIEXEC]" | head -1 | cut -f1` "bytes" | \
                tee -a $exp_logfile | tee -a $logfile
        do_mpirun 1 1 "" "" "du -h $vpic_dir/particle"
        message "-INFO- done"

        ### STAGE DATA OUT ###
        if [ x$jobdir != x$bbdir ]; then
            message "-INFO- staging data out... "
            mkdir -p $exp_jobdir/bb || die "mkdir $exp_jobdir/bb failed"
            message ""
            message "FROM : $exp_dir" ### BB ###
            message "  TO : $exp_jobdir/bb"  ### Luster ###
            message ""

            message "[DWCLI] dwcli" "stage out" "--session $dwsessid" "--configuration $dwconfid" \
                "--backing-path $exp_jobdir/bb/" "--dir ${exp_dir:${#DW_JOB_STRIPED}}"
            dwcli stage out --session $dwsessid --configuration $dwconfid \
                --backing-path $exp_jobdir/bb/ --dir ${exp_dir:${#DW_JOB_STRIPED}}

            message "-INFO- done"

            exp_dir=$exp_jobdir/bb
            vpic_dir=$exp_dir/vpic
        fi

        ### READ PATH ###
        if [ $do_querying -ne 0 ]; then
            query_particles $runtype $vpic_dir $pp
        fi
        ;;

    *)
        plfs_dir=$exp_dir/plfs
        vpic_dir=$exp_dir/vpic

        ### BOOTSTRAPING ###
        message "-INFO- creating more exp dirs..."
        do_mpirun 1 1 "" "" "mkdir -p $plfs_dir/particle"
        do_mpirun 1 1 "" "" "mkdir -p $vpic_dir"
        message "-INFO- done"

        ### WRITE PATH ###
        env_vars=(
            "VPIC_current_working_dir" "${vpic_dir}"
            "LD_PRELOAD" "${dfsu_prefix}/lib/libdeltafs-preload.so"
            "PRELOAD_Deltafs_root" "particle"
            "PRELOAD_Local_root" "${plfs_dir}"
            "PRELOAD_Bypass_deltafs_namespace" "1"
            "PRELOAD_Bypass_shuffle" ${BYPASS_SHUFFLE:-"0"}
            "PRELOAD_Bypass_write" ${BYPASS_WRITE:-"0"}
            "PRELOAD_Skip_mon" ${SKIP_MON:-"1"}
            "PRELOAD_No_epoch_pre_flushing" ${NO_PREFLUSH:-"0"}
            "PRELOAD_Enable_verbose_error" "1"
            "SHUFFLE_Virtual_factor" "1024"
            "SHUFFLE_Mercury_proto" ${MERCURY_PROTO:-"bmi+tcp"}
            "SHUFFLE_Buffer_per_queue" ${RPC_BUFFER:-"8192"}
            "SHUFFLE_Use_worker_thread" ${RPC_WORKER:-"1"}
            "SHUFFLE_Subnet" "${ip_subnet}"
            "PLFSDIR_Memtable_size" ${MEMTABLE_SIZE:-"32m"}
            "PLFSDIR_Index_buf_size" ${INDEX_BUF:-"2m"}
            "PLFSDIR_Data_buf_size" ${DATA_BUF:-"8m"}
            "PLFSDIR_Lg_parts" ${LG_PARTS:-"2"}
        )

        do_mpirun $cores $ppn env_vars[@] "$vpic_nodes" "${jobdir}/current-deck.op" \
            "${EXTRA_MPIOPTS-}"

        message ""
        message "-INFO- checking output size..."
        do_mpirun 1 1 "" "" "du -sb $plfs_dir/particle" | tee -a $exp_jobdir/outsize.txt
        echo "Output size:" `cat $exp_jobdir/outsize.txt | \
            grep -F -v "[MPIEXEC]" | head -1 | cut -f1` "bytes" | \
                tee -a $exp_logfile | tee -a $logfile
        do_mpirun 1 1 "" "" "du -h $plfs_dir/particle"
        message "-INFO- done"

        ### STAGE DATA OUT ###
        if [ x$jobdir != x$bbdir ]; then
            message "-INFO- staging data out... "
            mkdir -p $exp_jobdir/bb || die "mkdir $exp_jobdir/bb failed"
            message ""
            message "FROM : $exp_dir" ### BB ###
            message "  TO : $exp_jobdir/bb"  ### Luster ###
            message ""

            message "[DWCLI] dwcli" "stage out" "--session $dwsessid" "--configuration $dwconfid" \
                "--backing-path $exp_jobdir/bb/" "--dir ${exp_dir:${#DW_JOB_STRIPED}}"
            dwcli stage out --session $dwsessid --configuration $dwconfid \
                --backing-path $exp_jobdir/bb/ --dir ${exp_dir:${#DW_JOB_STRIPED}}

            message "-INFO- done"

            exp_dir=$exp_jobdir/bb
            plfs_dir=$exp_dir/plfs
            vpic_dir=$exp_dir/vpic
        fi

        ### READ PATH ###
        if [ $do_querying -eq 0 ]; then
            message ""
            message "!!! WARNING !!! write only - skipping read phase..."
            message ""
        else
            query_particles $runtype $exp_dir $pp
        fi
        ;;

    esac

    message ""
    message "--------------- [    OK    ] --------------"

    exp_logfile=""
}

#
# query_particles: query particle trajectories
#
# uses: $dfsu_prefix
#
# Arguments:
# @1 experiment type in {"baseline", "deltafs"}
# @2 vpic output directory
# @3 total number of particles
query_particles() {
    runtype=$1
    vpicout=$2
    pp=$3  ### for printing only ###

    case $runtype in
    "baseline")
        reader_bin="${dfsu_prefix}/bin/vpic-reader"
        ;;
    "deltafs")
        reader_bin="${dfsu_prefix}/bin/vpic-deltafs-reader"
        ;;
    *)
        die "query_particles: unknown runtype '$runtype'"
    esac

    nnum=$cores
    if [ $nnum -le $nodes ]; then
        qppn=1
    else
        qppn=0
    fi

    message ""
    message "=================================================================="
    message "!!! Query VPIC ($runtype) with $pp particles on $nnum cores !!!"
    message "------------"
    message "> Using ${reader_bin}"
    message "> Experiment dir is ${vpicout}"
    message "> Log to ${exp_logfile}"
    message "  (+) Log to ${logfile}"
    message "      (+) Log to STDOUT"
    message "=================================================================="
    message ""

    # Query particles to see when the DeltaFS approach breaks compared to old,
    # single-pass approach
    if [ $last -eq 1 ]; then
        do_mpirun $nnum $qppn "" $vpic_nodes "$reader_bin -i $vpicout"
    else
        do_mpirun $nnum $qppn "" $vpic_nodes "$reader_bin -i $vpicout -n 1"
    fi
}
